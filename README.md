# A Multi-Codec Distortion Dataset for Quality Assessment of Non-professional User-Generated 360° Videos
The Dataset and further details **will be available soon**

## Authors
Manav Arun Mehta, Jainil Kiran Patel, Akshit Choudhary, Daksh Chaudhary, Pramit Mazumdar  
Indian Institute of Information Technology Vadodara, India

## Abstract
The increasing accessibility of immersive technologies has empowered content creators to generate 360° videos in dynamic, real-world settings, often captured handheld and in motion. This variability introduces complexities in video quality and necessitates the assessment of Quality of Experience through subjective tests as a key aspect of developing novel immersive media systems.

In this project, we introduce **RUG360**, a novel Random User-Generated Content (RUGC) dataset comprising **81 transcoded sequences from 9 original videos**. To evaluate its characteristics, we conducted a **Subjective Video Quality Assessment (VQA)** study with **81 participants**, collecting **2,214 scores** using the **Modified Absolute Category Rating (Modified-ACR)** method. We then analyzed the dataset’s performance alongside objective quality metrics. The results indicate that the dataset’s perceptual quality reflects the capture of real-world scenarios, as opposed to the controlled conditions of laboratory environments.

## Usage
The RUG360 dataset is intended for research in **video quality assessment (VQA), quality of experience (QoE), and immersive media analysis**. Researchers can use this dataset to:
1. Benchmark their video quality models.
2. Train and evaluate new VQA algorithms.
3. Study the impact of real-world distortions in 360° videos.
   
## Contact
For any inquiries regarding the dataset, please contact the authors at **[202252344@iiitvadodara.ac.in]**.

